<!DOCTYPE html>
<html lang="zh-CN">
<head>
    <meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="referrer" content="strict-origin-when-cross-origin">
    <title>CorrectNav Research</title>
    <style>
        body {
            font-family: Lato, Arial, sans-serif;
            line-height: 1.6;
            color: #333;
            max-width: 1200px;
            margin: 0 auto;
            padding: 20px;
        }
        h1 {
            color: #d551c1;
            font-weight: 700;
            font-size: 2.8rem;
            margin-bottom: 1.5rem;
            line-height: 1.2;
        }
        h2 {
            color: #d551c1;
            font-weight: 700;
            font-size: 2.2rem;
            margin: 2rem 0 1rem;
        }
        .center {
            text-align: center;
        }
        .abstract {
            color: #3d85c6;
            margin-left: 15pt;
            font-size: 1.1rem;
        }
        .authors {
            color: #000000; /* Changed from blue to black */
            font-weight: 600; /* Reduced from 800 */
            font-size: 1.3rem; /* Reduced from 1.5rem */
            margin: 1.5rem 0;
        }
        .affiliation {
            color: #000000;
            font-size: 1.1rem; /* Reduced from 1.3rem */
            font-weight: 500; /* Reduced from 600 */
            margin-bottom: 2rem;
        }
        img {
            max-width: 100%;
            height: auto;
            display: block;
            margin: 30px auto;
        }
        hr {
            margin: 2.5rem 0;
            border: 0;
            height: 1px;
            background-color: #eee;
        }
        .video-container {
            position: relative;
            padding-bottom: 56.25%; /* 16:9 宽高比 */
            height: 0;
            overflow: hidden;
            margin: 30px 0;
        }
        .video-container iframe {
            position: absolute;
            top: 0;
            left: 0;
            width: 100%;
            height: 100%;
            border: none;
        }
        .video-caption {
            text-align: center;
            font-style: italic;
            color: #666;
            margin-top: 10px;
            font-size: 0.95rem;
        }
        .author-block {
            display: inline-block;
            margin-right: 5px;
        }
        .caption {
            text-align: center;
            font-style: italic;
            color: #666;
            margin-top: 10px;
            font-size: 0.95rem;
        }
    </style>
</head>
<body dir="ltr">
    <section class="center">
        <h1>CorrectNav: Self-Correction Flywheel Empowers Vision-Language-Action Navigation Model</h1>
        
        <div class="authors">
            <span class="author-block">
                Zhuoyuan Yu<sup>1,2*</sup>,
            </span>
            <span class="author-block">
                <a href="https://lyx0501.github.io/">Yuxing Long</a><sup>1,2*</sup>,
            </span>
            <span class="author-block">
                Zihan Yang<sup>1,2</sup>,
            </span>
            <span class="author-block">
                Chengyan Zeng<sup>2</sup>,
            </span>
            <span class="author-block">
                <a href="https://hwfan.io/about-me/">Hongwei Fan</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
                <a href="https://jiyao06.github.io/">Jiyao Zhang</a><sup>1,2</sup>,
            </span>
            <span class="author-block">
                <a href="https://zsdonghao.github.io/">Hao Dong</a><sup>1,2†</sup>
            </span>
        </div>

        <div class="affiliation">
            <span class="author-block"><sup>1</sup>CFCS, School of Computer Science, Peking University.   <sup>2</sup>PKU-AgiBot Lab.</span><br>
            <span class="author-block"><sup>*</sup>The first two authors contributed equally.</span><br>
            <span class="author-block"><sup>†</sup>Corresponding author.</span>
        </div>
    </section>

    <hr>

    <!-- Video section -->
    <section>
        <div class="video-container">
            <iframe src="https://www.youtube-nocookie.com/embed/JAj1npstnrE?modestbranding=1" 
                    frameborder="0" 
                    allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" 
                    allowfullscreen></iframe>
        </div>
        <p class="video-caption">Video: Demonstration of CorrectNav in various environments</p>
    </section>

    <section>
        <h2>Abstract</h2>
        <p class="abstract">
            Existing vision-and-language navigation models often deviate from the correct trajectory when executing instructions. However, these models lack effective error correction capability, hindering their recovery from errors. To address this challenge, we propose Self-correction Flywheel, a novel post-training paradigm. Instead of considering the model's error trajectories on the training set as a drawback, our paradigm emphasizes their significance as a valuable data source. We have developed a method to identify deviations in these error trajectories and devised innovative techniques to automatically generate self-correction data for perception and action. These self-correction data serve as fuel to power the model's continued training. The brilliance of our paradigm is revealed when we re-evaluate the model on the training set, uncovering new error trajectories. At this time, the self-correction flywheel begins to spin. Through multiple flywheel iterations, we progressively enhance our monocular RGB-based VLA navigation model CorrecctNav. Experiments on R2R-CE and RxR-CE benchmarks show CorrectNav achieves new state-of-the-art success rates of 65.1% and 69.3%, surpassing prior best VLA navigation models by 8.2% and 16.4%. Real robot tests in various indoor and outdoor environments demonstrate CorrectNav's superior capability of error correction, dynamic obstacle avoidance, and long instruction following.
        </p>
    </section>

    <hr>

    <section>
        <h2>Overview</h2>
        <img src="1.png" alt="CorrectNav Overview">
        <p class="caption">
            Figure 1: The overview of CorrectNav training. CorrectNav is first finetuned on the navigation tasks (Left), including action prediction and instruction generation. To enhance vision diversity, we implement a suite of domain randomization strategies. Subsequently, CorrectNav is post-trained with our proposed Self-correction Flywheel paradigm (Right). This paradigm operates in a continuous loop of model evaluation, deviation detection, data creation, and continued training. Specifically, the data creation part can automatically collect error-correcting trajectory and keyframe perception data. Through multiple training iterations, CorrectNav can learn how to recover from deviations.
        </p>
    </section>

    <hr>

    <!-- New SOTA Results section -->
    <section>
        <h2>SOTA Results</h2>
        <img src="2.png" alt="SOTA Results Comparison">
        <p class="caption">
            Table 1: Comparison with state-of-the-art methods on the Val-Unseen split of R2R-CE and RxR-CE. * indicates methods using the waypoint predictor. CorrectNav outperforms all methods that do not rely on simulator pre-trained waypoint predictors, even when those methods leverage additional inputs such as depth, panoramic views, and odometry.
        </p>
    </section>
</body>
</html>
